{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Exercise Sheet 3\n",
    "\n",
    "### Iftekher Aziz - 12338137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Aziz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports for all exercises\n",
    "import random\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Rewrite the following loop as a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 3),\n",
       " ('dog', 3),\n",
       " ('gave', 4),\n",
       " ('John', 4),\n",
       " ('the', 3),\n",
       " ('newspaper', 9)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper'] \n",
    "result = [] \n",
    "for word in sent: \n",
    "    word_len = (word, len(word)) \n",
    "    result.append(word_len) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 3),\n",
       " ('dog', 3),\n",
       " ('gave', 4),\n",
       " ('John', 4),\n",
       " ('the', 3),\n",
       " ('newspaper', 9)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original list of words\n",
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "\n",
    "# Using a list comprehension to create a new list of tuples\n",
    "# Each tuple contains a word from the original list and its length\n",
    "result = [(word, len(word)) for word in sent]\n",
    "\n",
    "# Printing the list of tuples with their lengths\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Pig Latin is a simple transformation of English text. Each word of the text is converted as follows: move any consonant (or consonant cluster) that appears at the start of the word to the end, then append \"ay\", e.g. \"string\" $\\rightarrow$ \"ingstray\". If a word starts with a vowel, just add \"way\" to the end, e.g. \"idle\" $\\rightarrow$ \"idleway\". \n",
    "\n",
    "Write a function to convert a word to Pig Latin. Test it with the words \"pig\", \"cheers\", and \"omelet\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['igpay', 'eerschay', 'omeletway']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_pig_latin(word):\n",
    "    vowels = 'aeiou'\n",
    "    # Check if the first letter is a vowel\n",
    "    if word[0].lower() in vowels:\n",
    "        return word + \"way\"\n",
    "    else:\n",
    "        # Find the index of the first vowel\n",
    "        for i, letter in enumerate(word):\n",
    "            if letter.lower() in vowels:\n",
    "                # Move the consonant cluster to the end and append \"ay\"\n",
    "                return word[i:] + word[:i] + \"ay\"\n",
    "        # If no vowel is found (which is unlikely in English), return the word as is with \"ay\"\n",
    "        return word + \"ay\"\n",
    "\n",
    "# Test the function with the given words\n",
    "test_words = [\"pig\", \"cheers\", \"omelet\"]\n",
    "result = [convert_to_pig_latin(word) for word in test_words]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Python's `random` module includes a function `choice()` which randomly chooses an item from a sequence, e.g. `choice('aehh ')` will produce one of four possible characters, with the letter \"h\" being twice as frequent as the others. Write a generator expression that produces a sequence of 500 randomly chosen letters drawn from the string \"aehh \", and put this expression inside a call to the `''.join()` function, to concatenate them into one long string. You should get a result that looks like uncontrolled sneezing or maniacal laughter: \"he  haha ee  heheeh eha\". Use `split()` and `join()` again to normalize the whitespace in this string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Sentence of Random Latters: aheehhahahe  aee  aaahhhh h eaeahhea hheaae heeaeah hhahheahahe haeeaae   eh hhhaeehh hhe ea  haahhahehehe hhe eaahhe aahhae hehe e h a  ee haaeaahaaeahhhaheaeh hhh aheeheeha eaehahahh hh  h e   ea ea ehheheeh h ahahae aha a  a hehahheea aaah ahhahhhehhh haee ee  hhhhe ha ahhheaa   aa ah haeeh hhhhhehhhhh aaaaeahaaah h ehhhaeaaaeehaeeaeeeah e hha a eaaaahhhh h hehah a  hahaheeehea hhhe a eeea hahahhhe ahhaheehhh haheeeah heah hh  heaehh eeeheaa  ehha ehhhh h  hhhe a eaaehhaah aha hhe hh h  hehhe \n",
      "\n",
      "After normalizing the whitespace: aheehhahahe aee aaahhhh h eaeahhea hheaae heeaeah hhahheahahe haeeaae eh hhhaeehh hhe ea haahhahehehe hhe eaahhe aahhae hehe e h a ee haaeaahaaeahhhaheaeh hhh aheeheeha eaehahahh hh h e ea ea ehheheeh h ahahae aha a a hehahheea aaah ahhahhhehhh haee ee hhhhe ha ahhheaa aa ah haeeh hhhhhehhhhh aaaaeahaaah h ehhhaeaaaeehaeeaeeeah e hha a eaaaahhhh h hehah a hahaheeehea hhhe a eeea hahahhhe ahhaheehhh haheeeah heah hh heaehh eeeheaa ehha ehhhh h hhhe a eaaehhaah aha hhe hh h hehhe\n"
     ]
    }
   ],
   "source": [
    "# Generate a sequence of 500 randomly chosen letters from the string \"aehh \"\n",
    "random_letters = ''.join(random.choice('aehh ') for _ in range(500))\n",
    "\n",
    "# Printing the Sentence of Random Latters\n",
    "print(\"A Sentence of Random Latters:\",random_letters,'\\n') \n",
    "\n",
    "# Normalize the whitespace in the generated string\n",
    "normalized_string = ' '.join(random_letters.split())\n",
    "\n",
    "# Printing after normalizing the whitespace\n",
    "print(\"After normalizing the whitespace:\",normalized_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Readability measures are used to score the reading difficulty of a text, for the purposes of selecting texts of appropriate difficulty for language learners. Let us define $\\mu_w$ to be the average number of letters per word, and $\\mu_s$ to be the average number of words per sentence, in a given text. The Automated Readability Index (ARI) of the text is defined to be: $4.71 \\mu_w + 0.5 \\mu_s - 21.43$. Compute the ARI score for the \"lore\" and \"learned\" genre of the Brown Corpus. Make use of the fact that `nltk.corpus.brown.words()` produces a sequence of words, while `nltk.corpus.brown.sents()` produces a sequence of sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.254756197101155, 11.926007043317348)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to compute the ARI score\n",
    "def compute_ari(genre):\n",
    "    words = brown.words(categories=genre)\n",
    "    sents = brown.sents(categories=genre)\n",
    "    \n",
    "    # Average number of letters per word (mu_w)\n",
    "    mu_w = sum(len(word) for word in words) / len(words)\n",
    "    \n",
    "    # Average number of words per sentence (mu_s)\n",
    "    mu_s = sum(len(sentence) for sentence in sents) / len(sents)\n",
    "    \n",
    "    # ARI formula\n",
    "    ari_score = 4.71 * mu_w + 0.5 * mu_s - 21.43\n",
    "    return ari_score\n",
    "\n",
    "# Compute ARI for the \"lore\" and \"learned\" genre\n",
    "ari_lore = compute_ari('lore')\n",
    "ari_learned = compute_ari('learned')\n",
    "\n",
    "ari_lore, ari_learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Define a variable `silly` to contain the string: 'newly formed bland ideas are inexpressible in an infuriating way'. Now write code to perform the following tasks:\n",
    "\n",
    "a) Split `silly` into a list of strings, one per word, using Python's `split()` operation, and save this to a variable called `bland`.  \n",
    "b) Extract the second letter of each word in `silly` and join them into a string, to get 'eoldrnnnna'.  \n",
    "c) Combine the words in `bland` back into a single string, using `join()`. Make sure the words in the resulting string are separated with whitespace.  \n",
    "d) Print the words of `silly` in alphabetical order, one per line.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second letters: eoldrnnnna \n",
      "\n",
      "Combined string: newly formed bland ideas are inexpressible in an infuriating way \n",
      "\n",
      "Sorted words: ['an', 'are', 'bland', 'formed', 'ideas', 'in', 'inexpressible', 'infuriating', 'newly', 'way']\n"
     ]
    }
   ],
   "source": [
    "# Define the variable 'silly'\n",
    "silly = 'newly formed bland ideas are inexpressible in an infuriating way'\n",
    "\n",
    "# a) Split 'silly' into a list of strings, one per word\n",
    "bland = silly.split()\n",
    "\n",
    "# b) Extract the second letter of each word and join them into a string\n",
    "second_letters = ''.join(word[1] for word in bland)\n",
    "\n",
    "# c) Combine the words in 'bland' back into a single string with spaces\n",
    "combined_string = ' '.join(bland)\n",
    "\n",
    "# d) Sort the words of 'silly' in alphabetical order and prepare for printing\n",
    "sorted_words = sorted(bland)\n",
    "\n",
    "print(\"Second letters:\",second_letters,'\\n')\n",
    "print(\"Combined string:\",combined_string,'\\n')\n",
    "print(\"Sorted words:\",sorted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Rewrite the following nested loop as a nested list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['attribution', 'confabulation', 'tenacious', 'elocution',\n",
    "         'sequoia', 'tenacious', 'unidirectional']\n",
    "vsequences = set()\n",
    "for word in words:\n",
    "    vowels = []\n",
    "    for char in word:\n",
    "        if char in 'aeiou':\n",
    "            vowels.append(char)\n",
    "    vsequences.add(''.join(vowels))\n",
    "sorted(vsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of words to process\n",
    "words = ['attribution', 'confabulation', 'tenacious', 'elocution', 'sequoia', 'tenacious', 'unidirectional']\n",
    "\n",
    "# Rewrite the nested loop as a nested list comprehension\n",
    "vsequences = {''.join([char for char in word if char in 'aeiou']) for word in words}\n",
    "\n",
    "# Sort the unique vowel sequences alphabetically\n",
    "sorted_vsequences = sorted(vsequences)\n",
    "\n",
    "# Printing the sorted list of unique vowel sequences\n",
    "sorted_vsequences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
